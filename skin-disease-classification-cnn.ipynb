{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('dark_background')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#öncelikle bu kısımda gerekli kütüphane ve modülleri import ve from ile ekliyoruz\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\n#from keras.datasets import dermnet\nfrom keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\nfrom keras.layers import Conv2D,MaxPooling2D\nimport os\n#import random\n#np.random.seed(0)\n#verisetimiz de 23 tane sınıf vardır her bir verinin boyutu 48*48 olarak ayarlanmıştır.\nnum_classes = 23\nimg_rows,img_cols = 48,48\nbatch_size = 32\n","metadata":{"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"#Derin öğrenme uygulamalarında sınıflandırma yaparken modeli kurarken veri seti eğitim ve test\n#olmak üzere ikiye ayrılır.Eğitim verisinde modeli kurarız test verisinde ise modeli degerlendiririz\n#burada veriseti yolunu gösteriyoruz ve verileri ayırıyoruz\n#verilerimiz 23 class ve 15557 eğitim verisi ve 4002 test/validation verisi olmak üzere 2 kısma ayrıldı\ntrain_data_dir = '../input/dermnet/train'#eğitim\nvalidation_data_dir = '../input/dermnet/test'#test\n\n#rescale=1./255\n#her dijital görüntü,0-255 aralığında değere sahip piksel tarafından oluşturulur. 0 siyah ve 255 beyazdır.\n#255 maksimum piksel değeri olduğundan Yeniden ölçeklendirme 1./255, [0,255] -> [0,1] aralığındaki her piksel değerini dönüştürmektir.\n\ntrain_datagen = ImageDataGenerator(\n\t\t\t\t\trescale=1./255,\n\t\t\t\t\trotation_range=30,\n\t\t\t\t\tshear_range=0.3,\n\t\t\t\t\tzoom_range=0.3,\n\t\t\t\t\twidth_shift_range=0.4,\n\t\t\t\t\theight_shift_range=0.4,\n\t\t\t\t\thorizontal_flip=True,\n\t\t\t\t\tfill_mode='nearest')\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\n#eğitim verileri ile ilgili bilgiler\n#Found 15557 images belonging to 23 classes.\ntrain_generator = train_datagen.flow_from_directory(\n\t\t\t\t\ttrain_data_dir,\n\t\t\t\t\tcolor_mode='grayscale',\n\t\t\t\t\ttarget_size=(img_rows,img_cols),\n\t\t\t\t\tbatch_size=batch_size,\n\t\t\t\t\tclass_mode='categorical',\n\t\t\t\t\tshuffle=True)\n#doğrulama /test\n#Found 4002 images belonging to 23 classes.\n\nvalidation_generator = validation_datagen.flow_from_directory(\n                            validation_data_dir,\n                            color_mode='grayscale',\n                            target_size=(img_rows,img_cols),\n                            batch_size=batch_size,\n                            class_mode='categorical',\n                            shuffle=True)\n\n","metadata":{"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Found 15557 images belonging to 23 classes.\nFound 4002 images belonging to 23 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"#plt.figure(0,figsize=(12,0))\n#for i in range(1,13):\n   # plt.subplot(3,4,i)\n   # plt.axis(\"off\")\n    # image=train_datagen[i],reshape(48,48,3)\n    #plt.imshow(image,cmap='gray')\n   # print(\"train_datagen:\",i)\n    \n    #plt.tight_layout()\n    #plt.show()\n","metadata":{"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Keras kütüphanesiyle sıralı katmanlardan oluşan sinir ağı modeli kullanırız.Model katman oluşturmamıza izin verir\nmodel = Sequential()\n#modele katman oluşturmak eklemmek için add() işlevini kullanırız.Öncelikle Conv2D katmanına uyguladık\n#Conv2D 2 piksellik bir küçültme sağlar.\n#MaxPooling kullanılarak kernel boyutlarında en büyük sayı alınmıştır\n#pooling ile gösterimin kayma boyutunu ağ içindeki parametreleri ve hesaplama sayısını azaltmak için kullandıkBununlada ağdaki uyumsuzluk kontrol edildi.\n#Maxpool2D İLE HER İKİ YÖNDEN BOYUTLAR YARIYA İNDİRİLDİ\n#Sinir ağı eğitimi konusunda en iyi sonucu relu fonksiyonu veriyor Bu yüzden burda aktivasyon fonksiyonumuz relu\n# Block-1\n\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n#2 katmanımızda da önce Conv2D uyguladık verimiz 48,48 boyutlu burada activasyon  fonksiyonu olarak elu kullandık\n#Düzenli ve stabil eğitim için BatchNormalization() katmanını uyguladık.\n#Bununla eğitim süresini azaltabilir ve modelin daha iyi performans göstermesi sağlanabilir.\n\n# Block-2 \n\nmodel.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n#Diğer katmanlarda da yine benzer işlemler tekrarlanıyor.Burada dikkat etmemiz gereken bir diğer katman dropout()\n#Dropout()ile 0.20 giriş değeri devre dışı bırakılıyor.\n#ilk Conv katmanında görüntünün Width ve height değerleri mutlaka girilmelidir.Bu degerlere göre filtreleme işlemi yapılacaktır.\n#\n\n# Block-3\n\nmodel.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Block-4 \n\nmodel.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Block-5\n\nmodel.add(Flatten())\nmodel.add(Dense(64,kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n#Son olarak Flatten ve dense uygulanır.\n#Flatten katmanı tek boyutlu diziye dönüştürür.\n#Dense katman tür anlamına gelmektedir.\n#Derin öğrenme yöntemlerinin doğrusal olmayan ilişkileri modellemesi için her düğümde gerçekleşen işlemler doğrusal olmayan bir akt.fonksiyonundan geçirilir.\n#Akt. fonksiyonu ağırlıklı toplamı hesaplar ve nöronun aktive edilip edilmeyeceğine karar verir.\n# Block-6\n\nmodel.add(Dense(64,kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Block-7\n\nmodel.add(Dense(num_classes,kernel_initializer='he_normal'))\nmodel.add(Activation('softmax'))\n\nprint(model.summary())\n\n\n","metadata":{"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_40 (Conv2D)           (None, 48, 48, 32)        320       \n_________________________________________________________________\nactivation_55 (Activation)   (None, 48, 48, 32)        0         \n_________________________________________________________________\nbatch_normalization_50 (Batc (None, 48, 48, 32)        128       \n_________________________________________________________________\nconv2d_41 (Conv2D)           (None, 48, 48, 32)        9248      \n_________________________________________________________________\nactivation_56 (Activation)   (None, 48, 48, 32)        0         \n_________________________________________________________________\nbatch_normalization_51 (Batc (None, 48, 48, 32)        128       \n_________________________________________________________________\nmax_pooling2d_20 (MaxPooling (None, 24, 24, 32)        0         \n_________________________________________________________________\ndropout_30 (Dropout)         (None, 24, 24, 32)        0         \n_________________________________________________________________\nconv2d_42 (Conv2D)           (None, 24, 24, 64)        18496     \n_________________________________________________________________\nactivation_57 (Activation)   (None, 24, 24, 64)        0         \n_________________________________________________________________\nbatch_normalization_52 (Batc (None, 24, 24, 64)        256       \n_________________________________________________________________\nconv2d_43 (Conv2D)           (None, 24, 24, 64)        36928     \n_________________________________________________________________\nactivation_58 (Activation)   (None, 24, 24, 64)        0         \n_________________________________________________________________\nbatch_normalization_53 (Batc (None, 24, 24, 64)        256       \n_________________________________________________________________\nmax_pooling2d_21 (MaxPooling (None, 12, 12, 64)        0         \n_________________________________________________________________\ndropout_31 (Dropout)         (None, 12, 12, 64)        0         \n_________________________________________________________________\nconv2d_44 (Conv2D)           (None, 12, 12, 128)       73856     \n_________________________________________________________________\nactivation_59 (Activation)   (None, 12, 12, 128)       0         \n_________________________________________________________________\nbatch_normalization_54 (Batc (None, 12, 12, 128)       512       \n_________________________________________________________________\nconv2d_45 (Conv2D)           (None, 12, 12, 128)       147584    \n_________________________________________________________________\nactivation_60 (Activation)   (None, 12, 12, 128)       0         \n_________________________________________________________________\nbatch_normalization_55 (Batc (None, 12, 12, 128)       512       \n_________________________________________________________________\nmax_pooling2d_22 (MaxPooling (None, 6, 6, 128)         0         \n_________________________________________________________________\ndropout_32 (Dropout)         (None, 6, 6, 128)         0         \n_________________________________________________________________\nconv2d_46 (Conv2D)           (None, 6, 6, 256)         295168    \n_________________________________________________________________\nactivation_61 (Activation)   (None, 6, 6, 256)         0         \n_________________________________________________________________\nbatch_normalization_56 (Batc (None, 6, 6, 256)         1024      \n_________________________________________________________________\nconv2d_47 (Conv2D)           (None, 6, 6, 256)         590080    \n_________________________________________________________________\nactivation_62 (Activation)   (None, 6, 6, 256)         0         \n_________________________________________________________________\nbatch_normalization_57 (Batc (None, 6, 6, 256)         1024      \n_________________________________________________________________\nmax_pooling2d_23 (MaxPooling (None, 3, 3, 256)         0         \n_________________________________________________________________\ndropout_33 (Dropout)         (None, 3, 3, 256)         0         \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 2304)              0         \n_________________________________________________________________\ndense_15 (Dense)             (None, 64)                147520    \n_________________________________________________________________\nactivation_63 (Activation)   (None, 64)                0         \n_________________________________________________________________\nbatch_normalization_58 (Batc (None, 64)                256       \n_________________________________________________________________\ndropout_34 (Dropout)         (None, 64)                0         \n_________________________________________________________________\ndense_16 (Dense)             (None, 64)                4160      \n_________________________________________________________________\nactivation_64 (Activation)   (None, 64)                0         \n_________________________________________________________________\nbatch_normalization_59 (Batc (None, 64)                256       \n_________________________________________________________________\ndropout_35 (Dropout)         (None, 64)                0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 23)                1495      \n_________________________________________________________________\nactivation_65 (Activation)   (None, 23)                0         \n=================================================================\nTotal params: 1,329,207\nTrainable params: 1,327,031\nNon-trainable params: 2,176\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.optimizers import RMSprop,SGD,Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint('skin_disease.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks = [earlystop,checkpoint,reduce_lr]\n\n#modeli derlerken compile fonksiyonunu kullanırız.Bir çok parametre alır fakat biz burada 3 tane kullandık.\n#optimizer öğrenme oranı->Adam en yaygın kullanılır.\n#metric için accuracy-doğruluk değerini verdik\n#kayıp fonksiyonu loss için ise categorical_crossentropy kullandık.\n#Yapay Sinir Ağları çalışmalarında maliyet fonksiyonu önemlidir ve minimum olması gerekir.\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])\n\n#Epochs devir sayısı:Bu değeri 25 olarak belirledik verisetinin kaç kez model üzerinden geçip eğitileceğini gösterir\n#sayıyı küçük verirsek eğitim kısa sürer.\n#batchsize aynı anda eğitilen veri sayısıdır.yani burda 4002 tane veriyi aynı anda eğitime sokmuş oluruz.\n\nnb_train_samples = 15557\nnb_validation_samples = 4002\nepochs=25\n#Validation doğrulama seti anlamına gelmektedir.Eğitimin model performansını test etmek için kullanılmaktadır.\n#Model eğitilirken fit () işlevini kullanıyoruz\n###model çalıştır###\nhistory=model.fit_generator(\n                train_generator,\n                steps_per_epoch=nb_train_samples//batch_size,\n                epochs=epochs,\n                callbacks=callbacks,\n                validation_data=validation_generator,\n                validation_steps=nb_validation_samples//batch_size)","metadata":{"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/25\n 21/486 [>.............................] - ETA: 4:34 - loss: 4.6384 - accuracy: 0.0553","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-370e2c6a1bbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 validation_steps=nb_validation_samples//batch_size)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')\n \n#aktivasyon fonksiyonları, activation functions\n \n    \ndef step(x):\n    return np.array(x > 0, dtype=np.int)\n \ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n \ndef relu(x):\n    return np.maximum(0, x)\n \ndef softmax(x):\n    return np.exp(x) / np.sum(np.exp(x))\n \ndef softplus(x):\n    return np.log(1.0 + np.exp(x))\n \ndef tanh(x):\n    return np.tanh(x)\n \ndef swish(x):\n    #return x*sigmoid(x)\n    return x*(1 / (1 + np.exp(-x)))\n \ndef prelu(x,alpha):\n    a = []\n    for item in x:\n        if item < 0:\n            a.append(alpha*item)\n        else:\n            a.append(item)\n    return a\n \ndef elu(x,alpha):\n    a = []\n    for item in x:\n        if item >= 0:\n            a.append(item)\n        else:\n            a.append(alpha * (np.exp(item)-1))\n    return a\n \nx = np.arange(-5., 5., 0.1)\n \nstep=step(x)\nsigmoid=sigmoid(x)\nrelu=relu(x)\nsoftmax=softmax(x)\nsoftplus=softplus(x)\ntanh=tanh(x)\nprelu=prelu(x,0.1)\nelu=elu(x,1.0)\nswish=swish(x)\n \n#grafik çizimleri, plotting\n \nplt.figure()\nplt.xlabel(\"Girdiler\")\nplt.ylabel(\"Fonksiyon Çıktıları\")\nplt.grid(True)\nplt.plot(x,step, label=\"Step\", color='C0', lw=3)\nplt.plot(x,sigmoid, label=\"Sigmoid\", color='C1', lw=3)\n\nplt.plot(x,softmax, label=\"Softmax\", color='C3', lw=3)\nplt.plot(x,softplus, label=\"SoftPlus\", color='C4', lw=3)\nplt.plot(x,tanh, label=\"TanH\", color='C5', lw=3)\nplt.plot(x,prelu, label=\"PReLU\", color='C6', lw=3)\nplt.plot(x,elu, label=\"ELU\", color='C8', lw=3)\nplt.plot(x,swish, label=\"Swish\", color='C9', lw=3)\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}
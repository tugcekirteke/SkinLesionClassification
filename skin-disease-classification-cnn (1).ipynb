{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('dark_background')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#öncelikle bu kısımda gerekli kütüphane ve modülleri import ve from ile ekliyoruz\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\n#from keras.datasets import dermnet\nfrom keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\nfrom keras.layers import Conv2D,MaxPooling2D\nimport os\n#import random\n#np.random.seed(0)\n#verisetimiz de 23 tane sınıf vardır her bir verinin boyutu 48*48 olarak ayarlanmıştır.\nnum_classes = 23\nimg_rows,img_cols = 48,48\nbatch_size = 32\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Derin öğrenme uygulamalarında sınıflandırma yaparken modeli kurarken veri seti eğitim ve test\n#olmak üzere ikiye ayrılır.Eğitim verisinde modeli kurarız test verisinde ise modeli degerlendiririz\n#burada veriseti yolunu gösteriyoruz ve verileri ayırıyoruz\n#verilerimiz 23 class ve 15557 eğitim verisi ve 4002 test/validation verisi olmak üzere 2 kısma ayrıldı\ntrain_data_dir = '../input/dermnet/train'#eğitim\nvalidation_data_dir = '../input/dermnet/test'#test\n\n#rescale=1./255\n#her dijital görüntü,0-255 aralığında değere sahip piksel tarafından oluşturulur. 0 siyah ve 255 beyazdır.\n#255 maksimum piksel değeri olduğundan Yeniden ölçeklendirme 1./255, [0,255] -> [0,1] aralığındaki her piksel değerini dönüştürmektir.\n\ntrain_datagen = ImageDataGenerator(\n\t\t\t\t\trescale=1./255,\n\t\t\t\t\trotation_range=30,\n\t\t\t\t\tshear_range=0.3,\n\t\t\t\t\tzoom_range=0.3,\n\t\t\t\t\twidth_shift_range=0.4,\n\t\t\t\t\theight_shift_range=0.4,\n\t\t\t\t\thorizontal_flip=True,\n\t\t\t\t\tfill_mode='nearest')\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\n#eğitim verileri ile ilgili bilgiler\n#Found 15557 images belonging to 23 classes.\ntrain_generator = train_datagen.flow_from_directory(\n\t\t\t\t\ttrain_data_dir,\n\t\t\t\t\tcolor_mode='grayscale',\n\t\t\t\t\ttarget_size=(img_rows,img_cols),\n\t\t\t\t\tbatch_size=batch_size,\n\t\t\t\t\tclass_mode='categorical',\n\t\t\t\t\tshuffle=True)\n#doğrulama /test\n#Found 4002 images belonging to 23 classes.\n\nvalidation_generator = validation_datagen.flow_from_directory(\n                            validation_data_dir,\n                            color_mode='grayscale',\n                            target_size=(img_rows,img_cols),\n                            batch_size=batch_size,\n                            class_mode='categorical',\n                            shuffle=True)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.figure(0,figsize=(12,0))\n#for i in range(1,13):\n   # plt.subplot(3,4,i)\n   # plt.axis(\"off\")\n    # image=train_datagen[i],reshape(48,48,3)\n    #plt.imshow(image,cmap='gray')\n   # print(\"train_datagen:\",i)\n    \n    #plt.tight_layout()\n    #plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Keras kütüphanesiyle sıralı katmanlardan oluşan sinir ağı modeli kullanırız.Model katman oluşturmamıza izin verir\nmodel = Sequential()\n#modele katman oluşturmak eklemmek için add() işlevini kullanırız.Öncelikle Conv2D katmanına uyguladık\n#Conv2D 2 piksellik bir küçültme sağlar.\n#MaxPooling kullanılarak kernel boyutlarında en büyük sayı alınmıştır\n#pooling ile gösterimin kayma boyutunu ağ içindeki parametreleri ve hesaplama sayısını azaltmak için kullandıkBununlada ağdaki uyumsuzluk kontrol edildi.\n#Maxpool2D İLE HER İKİ YÖNDEN BOYUTLAR YARIYA İNDİRİLDİ\n#Sinir ağı eğitimi konusunda en iyi sonucu relu fonksiyonu veriyor Bu yüzden burda aktivasyon fonksiyonumuz relu\n# Block-1\n\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n#2 katmanımızda da önce Conv2D uyguladık verimiz 48,48 boyutlu burada activasyon  fonksiyonu olarak elu kullandık\n#Düzenli ve stabil eğitim için BatchNormalization() katmanını uyguladık.\n#Bununla eğitim süresini azaltabilir ve modelin daha iyi performans göstermesi sağlanabilir.\n\n# Block-2 \n\nmodel.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n#Diğer katmanlarda da yine benzer işlemler tekrarlanıyor.Burada dikkat etmemiz gereken bir diğer katman dropout()\n#Dropout()ile 0.20 giriş değeri devre dışı bırakılıyor.\n#ilk Conv katmanında görüntünün Width ve height değerleri mutlaka girilmelidir.Bu degerlere göre filtreleme işlemi yapılacaktır.\n#\n\n# Block-3\n\nmodel.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Block-4 \n\nmodel.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Block-5\n\nmodel.add(Flatten())\nmodel.add(Dense(64,kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n#Son olarak Flatten ve dense uygulanır.\n#Flatten katmanı tek boyutlu diziye dönüştürür.\n#Dense katman tür anlamına gelmektedir.\n#Derin öğrenme yöntemlerinin doğrusal olmayan ilişkileri modellemesi için her düğümde gerçekleşen işlemler doğrusal olmayan bir akt.fonksiyonundan geçirilir.\n#Akt. fonksiyonu ağırlıklı toplamı hesaplar ve nöronun aktive edilip edilmeyeceğine karar verir.\n# Block-6\n\nmodel.add(Dense(64,kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Block-7\n\nmodel.add(Dense(num_classes,kernel_initializer='he_normal'))\nmodel.add(Activation('softmax'))\n\nprint(model.summary())\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import RMSprop,SGD,Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint('skin_disease.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks = [earlystop,checkpoint,reduce_lr]\n\n#modeli derlerken compile fonksiyonunu kullanırız.Bir çok parametre alır fakat biz burada 3 tane kullandık.\n#optimizer öğrenme oranı->Adam en yaygın kullanılır.\n#metric için accuracy-doğruluk değerini verdik\n#kayıp fonksiyonu loss için ise categorical_crossentropy kullandık.\n#Yapay Sinir Ağları çalışmalarında maliyet fonksiyonu önemlidir ve minimum olması gerekir.\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])\n\n#Epochs devir sayısı:Bu değeri 25 olarak belirledik verisetinin kaç kez model üzerinden geçip eğitileceğini gösterir\n#sayıyı küçük verirsek eğitim kısa sürer.\n#batchsize aynı anda eğitilen veri sayısıdır.yani burda 4002 tane veriyi aynı anda eğitime sokmuş oluruz.\n\nnb_train_samples = 15557\nnb_validation_samples = 4002\nepochs=25\n#Validation doğrulama seti anlamına gelmektedir.Eğitimin model performansını test etmek için kullanılmaktadır.\n#Model eğitilirken fit () işlevini kullanıyoruz\n###model çalıştır###\nhistory=model.fit_generator(\n                train_generator,\n                steps_per_epoch=nb_train_samples//batch_size,\n                epochs=epochs,\n                callbacks=callbacks,\n                validation_data=validation_generator,\n                validation_steps=nb_validation_samples//batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')\n \n#aktivasyon fonksiyonları, activation functions\n \n    \ndef step(x):\n    return np.array(x > 0, dtype=np.int)\n \ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n \ndef relu(x):\n    return np.maximum(0, x)\n \ndef softmax(x):\n    return np.exp(x) / np.sum(np.exp(x))\n \ndef softplus(x):\n    return np.log(1.0 + np.exp(x))\n \ndef tanh(x):\n    return np.tanh(x)\n \ndef swish(x):\n    #return x*sigmoid(x)\n    return x*(1 / (1 + np.exp(-x)))\n \ndef prelu(x,alpha):\n    a = []\n    for item in x:\n        if item < 0:\n            a.append(alpha*item)\n        else:\n            a.append(item)\n    return a\n \ndef elu(x,alpha):\n    a = []\n    for item in x:\n        if item >= 0:\n            a.append(item)\n        else:\n            a.append(alpha * (np.exp(item)-1))\n    return a\n \nx = np.arange(-5., 5., 0.1)\n \nstep=step(x)\nsigmoid=sigmoid(x)\nrelu=relu(x)\nsoftmax=softmax(x)\nsoftplus=softplus(x)\ntanh=tanh(x)\nprelu=prelu(x,0.1)\nelu=elu(x,1.0)\nswish=swish(x)\n \n#grafik çizimleri, plotting\n \nplt.figure()\nplt.xlabel(\"Girdiler\")\nplt.ylabel(\"Fonksiyon Çıktıları\")\nplt.grid(True)\nplt.plot(x,step, label=\"Step\", color='C0', lw=3)\nplt.plot(x,sigmoid, label=\"Sigmoid\", color='C1', lw=3)\n\nplt.plot(x,softmax, label=\"Softmax\", color='C3', lw=3)\nplt.plot(x,softplus, label=\"SoftPlus\", color='C4', lw=3)\nplt.plot(x,tanh, label=\"TanH\", color='C5', lw=3)\nplt.plot(x,prelu, label=\"PReLU\", color='C6', lw=3)\nplt.plot(x,elu, label=\"ELU\", color='C8', lw=3)\nplt.plot(x,swish, label=\"Swish\", color='C9', lw=3)\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}